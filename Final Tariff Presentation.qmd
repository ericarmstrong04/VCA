---
title: "Regression Modeling & Forecasts: Egg Prices & Their Potential Relation to Tariffs"
author: "Eric Armstrong"
format: 
    html:
        mainfont: "Gill Sans"
        toc: true
        toc-title: "Index"
        toc-depth: 2
        smooth-scroll: true
        toc-location: left
editor: visual
jupyter: python3
output-file: "Final Tariff Presentation.html"
output-dir: "/Users/ericarmstrong/Desktop"
---

## Introduction

Over the course of the past 2 weeks, my work primarily consisted of building an OLS Regression Model to track how egg prices impacted consumption, with a specific focus on consumer spending patterns. This project's main goal was to track how egg consumption (the predictor variable) acted in relation to the prices of eggs, while also finding which combination of external factors (the control variables) would provide the strongest statistical model. Below, I showcase a few of my most notable findings, and the models which I believe are most useful to VISA.

## Logistics

All data is public and was pulled from the US Census Bureau, and the Bureau of Economic Analysis (BEA). The data is monthly and begins coverage from 01-01-2018 to 05-01-2025.\
\
Below is a key for what each coefficient in the data stands for:

UFMEN: CPI-U: Eggs  (NSA, 1982-84=100)

UFEC: CPI-U: Real Personal Egg Consumption Expenditures, Chained Dollars (SA)

PCE: Personal consumption expenditures

VSMINN: Visa Nondiscretionary Spending Momentum Index (NSA, \>100=Strengthening)

VSMIDN: Visa Discretionary Spending Momentum Index (NSA, \>100=Strengthening)

CCOND: University of Michigan: Current Economic Conditions (NSA, Q1-66=100)

RECPROB: Probability of US Recession 12-Mo Ahead, as Predicted by the Treasury Spread (%)

PXEA: Export Price Index: All Exports (NSA, 2000=100)

PMEA: Import Price Index: All Imports (NSA, 2000=100)

NRSI511N: Retail Sales: Supermarkets & Other Grocery \[ex Convenience Stores\](NSA, Mil.US\$)

NRSV2N: Retail Sales: Food Services & Drinking Places (NSA, Mil.\$)

Education: Real Personal Consumption Expenditures, Chained Dollars for Education

FNBOPC: Food and beverages purchased for off-premises consumption

## Notable Regression Models

The following regression model provided me with the highest R\^2 value of .989, or 98.9% of the variance in the data could be explained by the model, making it very statistically powerful. For control variables, I used PCE, VSMINN, VSMIDN, CCOND, RECPROB, PXEA, PMEA, NRSI511N, Education and FNBOPC.

```{python}
#| echo: false
import os
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Set working directory
os.chdir(os.path.expanduser("/Users/ericarmstrong/Desktop"))

# Load and parse dates
df = pd.read_csv("table_final.csv")
df['date'] = pd.to_datetime(df['date'])

# Group and average duplicate entries
df_clean = df.groupby(['date', 'seriesName'], as_index=False)['data'].mean()

# Pivot long → wide
df_wide = df_clean.pivot(index='date', columns='seriesName', values='data')

# Keep only target variables
target_vars = ['UFMEN', 'UFEC', 'NRSI511N', 'CCIN', 'NRSV2N', 'CCOND', 'RECPROB', 'VSMINN', 'VSMIDN', 
               'Personal consumption expenditures (PCE)', 'Education', 'PXEA', 'PMEA']

for var in target_vars:
    if var not in df_wide.columns:
        raise ValueError(f"Missing required column: {var}")

# Keep only those + date
df_model = df_wide[target_vars].copy()
df_model = df_model.dropna()  # Drop rows with any NaNs

# Convert to (if needed)
df_model = df_model.apply(pd.to_numeric, errors='coerce')
df_model = df_model.dropna()

# Compute percentage change
df_model = df_model.pct_change().dropna()

# Join with date
df_model['date'] = df_model.index
df_model = df_model[['date'] + target_vars]

df_wide = df_wide.rename(columns={'Personal consumption expenditures (PCE)': 'PCE'})
df_wide = df_wide.rename(columns={'Food and beverages purchased for off-premises consumption': 'FNBOPC'})

df_model = df_model[df_model['date'] >= pd.to_datetime('2018-01-01')]

formula5 = 'UFMEN ~ UFEC + PCE + VSMINN + CCOND + RECPROB + PXEA + PMEA + NRSI511N + VSMIDN + Education + FNBOPC'
model5 = smf.ols(formula5, data=df_wide).fit()
print(model5.summary())
```

### Important Findings

-   The p-value of our predictor variable, consumer spending on eggs, is nearly 0; signifies that there is extremely strong statistically significant evidence that consumer spending directly impacts the price of eggs.

-   Since our coefficient for the following variable is negative, we can infer that as the price of eggs rises, consumption rates slightly drop.\

-   With respect to control variables, spending momentum and the export import index were the only variables which crossed the significance threshold of p \< 0.05. Education with a p-value of 0.061 was very close, however the p-value was a little too large to meet the statistically significant benchmark.

-   We can infer that there is statistically significant evidence that spending momentum, alongside export and import index rates affect the price of eggs.

### Slight Problem: Multicollinearity & Overfitting

While the following model was able to push out such a high R\^2 value, there were some glaring issues with the model which could not be overlooked, with the main one being the super high condition number suggesting the presence of multicollinearity. To combat this issue, I conducted a VIF test on my parameters to see which ones were not absolutely necessary for the regression model. Below is the redesigned model alongside the VIF testing results to illustrate which parameters were causing issues.

```{python}
#| echo: false
import os
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Set working directory
os.chdir(os.path.expanduser("/Users/ericarmstrong/Desktop"))

# Load and parse dates
df = pd.read_csv("table_final.csv")
df['date'] = pd.to_datetime(df['date'])

# Group and average duplicate entries
df_clean = df.groupby(['date', 'seriesName'], as_index=False)['data'].mean()

# Pivot long → wide
df_wide = df_clean.pivot(index='date', columns='seriesName', values='data')

# Rename columns for easier formula access
df_wide = df_wide.rename(columns={
    'Personal consumption expenditures (PCE)': 'PCE',
    'Food and beverages purchased for off-premises consumption': 'FNBOPC'
})

# Keep only target variables
target_vars = ['UFMEN', 'UFME', 'UFEC', 'NRSI511N', 'CCIN', 'NRSV2N', 'CCOND', 'RECPROB', 'VSMINN', 'VSMIDN', 
               'PCE', 'Education', 'PXEA', 'PMEA', 'FNBOPC']

for var in target_vars:
    if var not in df_wide.columns:
        raise ValueError(f"Missing required column: {var}")

# Filter and clean model data
df_model = df_wide[target_vars].copy()
df_model = df_model.apply(pd.to_numeric, errors='coerce').dropna()
df_model = df_model.pct_change().dropna()

vif_vars = ['UFEC', 'PMEA', 'PXEA', 'NRSI511N', 'CCIN', 'CCOND', 'VSMINN', 'NRSV2N', 'VSMIDN']
X = df_model[vif_vars].copy()
X = sm.add_constant(X)

# Compute VIF for each variable
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Print results
print("\n=== Variance Inflation Factors ===")
print(vif_data.sort_values(by="VIF", ascending=False))

formula4 = "UFME ~ UFEC + PMEA + PXEA + NRSI511N + CCIN + CCOND + VSMINN + NRSV2N + VSMIDN"
model4 = smf.ols(formula4, data=df_model).fit()
print(model4.summary())
```

### Brief Summary of Findings:

-   None of the values in the VIF table fall above 3.6 \< 10, signifying that all the following indices should not cause any issues of multicollinearity.

-   The high R\^2 value of .947 signifies that the model is strong, as 94.7% of the variance in the data can be explained by it.

-   Just like the last model, we see the super low p-value of nearly 0 for the egg consumption variable, reinforcing the statistical significance and negative correlation which egg consumption has on its prices.

-   unlike the previous model, none of the control coefficients p-values fall under the significance threshold of p \< 0.05, so there is not enough statistically significant evidence to reject the null hypothesis for any of these factors.

Finally, I included a residual plot below as a final test to confirm the model met all conditions safely. Since the residuals are randomly spread with no pattern, this confirms the model should be accurate without any issues of multicollinearity.

```{python}
#| echo: false
import matplotlib.pyplot as plt
residuals = model4.resid
fitted = model4.fittedvalues

plt.scatter(fitted, residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Fitted values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()
```

## EDA & Correlation Models

```{python}
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt

df_plot = df_model.loc[(df_model.index >= "2023-01-01") & (df_model.index <= "2025-05-01")]

# Plot the two variables (update names based on actual column headers)
plt.figure(figsize=(10, 6))
plt.plot(df_plot.index, df_plot["UFMEN"], label="CPI-U: Eggs (NSA)")
plt.plot(df_plot.index, df_plot["UFEC"], label="Real Personal Egg Consumption Expenditures")
plt.xlabel("Date")
plt.ylabel("Growth Rate")
plt.title("Egg Prices & Consumption Over Time (2023–2025)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```

```{python}
#| echo: false
import matplotlib.pyplot as plt
from PIL import Image
import os

# Path to your image on desktop
img_path = os.path.expanduser("/Users/ericarmstrong/Desktop/UFMENvsUFEC.png")

# Open and show the image
img = Image.open(img_path)
plt.imshow(img)
plt.axis('off')  # Hide axes
plt.show()
```

-   The following two graphs illustrate the negative correlation between the price of eggs, and consumer spending patterns.

-   As the price of eggs increases, consumer spending drops and vice versa.

```{python}
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt

df_plot = df_model.loc[(df_model.index >= "2023-01-01") & (df_model.index <= "2025-05-01")]

fig, ax1 = plt.subplots(figsize=(10, 6))

# Primary y-axis (left)
ax1.plot(df_plot.index, df_plot["UFMEN"], color='tab:blue', label="CPI-U: Eggs (NSA)")
ax1.set_xlabel("Date")
ax1.set_ylabel("Egg Prices", color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Secondary y-axis (right)
ax2 = ax1.twinx()
ax2.plot(df_plot.index, df_plot["PXEA"], color='tab:red', label="Export Price Index: All Exports (NSA, 2000=100)")
ax2.set_ylabel("Price Index", color='tab:red')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Title and layout
plt.title("Egg Prices & Exports Over Time (2023–2025)")
fig.tight_layout()
plt.grid(True)
plt.show()
```

```{python}
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt

df_plot = df_model.loc[(df_model.index >= "2023-01-01") & (df_model.index <= "2025-05-01")]

fig, ax1 = plt.subplots(figsize=(10, 6))

# Primary y-axis (left)
ax1.plot(df_plot.index, df_plot["UFMEN"], color='tab:blue', label="CPI-U: Eggs (NSA)")
ax1.set_xlabel("Date")
ax1.set_ylabel("Egg Prices", color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Secondary y-axis (right)
ax2 = ax1.twinx()
ax2.plot(df_plot.index, df_plot["PMEA"], color='tab:red', label="Import Price Index: All Imports (NSA, 2000=100)")
ax2.set_ylabel("Price Index", color='tab:red')
ax2.tick_params(axis='y', labelcolor='tab:red')

# Title and layout
plt.title("Egg Prices & Imports Over Time (2023–2025)")
fig.tight_layout()
plt.grid(True)
plt.show()
```

-   Export index and egg prices closely track each other, shows the positive correlation.

-   Import index is a little more variate, but negative correlation between the two can be visibly seen over some quarterly spans just as the regression model suggested.

## Relevant Forecasts & Inferences Based Off Them

Below, I included some forecast graphs which I believed were relevant to the project. I chose indices within the regression model that may give us further insight about how consumer spending patterns and the prices of eggs may change in the future. Additionally, I also tried to synthesize the information with the recent tariff changes, as this was a strong point of interest for Publix.

```{python}
#| echo: false
import os
import pandas as pd
from prophet import Prophet
from matplotlib.backends.backend_pdf import PdfPages

os.chdir(os.path.expanduser("/Users/ericarmstrong/Desktop"))

df = pd.read_csv("table_final.csv")
df.head()

df.rename(columns={"date": "ds", "data": "y"}, inplace=True)
# Convert date column to datetime format if needed
df["ds"] = pd.to_datetime(df["ds"])
subdfs = {name: group for name, group in df.groupby('seriesName')}
```

### Egg Prices

```{python}
#| echo: false
df_nrs = subdfs["UFMEN"]
df_nrs = df_nrs[df_nrs["ds"] >= "2018-01-01"]

m6 = Prophet()
m6.fit(df_nrs)

future6 = m6.make_future_dataframe(periods=365)
forecast6 = m6.predict(future6)

fig11 = m6.plot(forecast6)
fig12 = m6.plot_components(forecast6)
```

-   Egg prices have been on the steady, very subtle rise prior to the 2025 shortage

-   Around the end of 2024 and the beginning of 2025, we see the huge price jump in eggs which was caused by the bird flu. 

-   From this graph, prophet estimates that egg prices may potentially jump super high, but more generally will still steadily increase

-   Signifies prices will not be permanently damaged by the shortage.

### Retail Sales for Supermarkets & Other Grocery Stores

```{python}
#| echo: false
df_nrs2 = subdfs["NRSI511N"]
df_nrs2 = df_nrs2[df_nrs2["ds"] >= "2018-01-01"]

m1 = Prophet()
m1.fit(df_nrs2)

future1 = m1.make_future_dataframe(periods=365)
forecast1 = m1.predict(future1)

fig1 = m1.plot(forecast1)
fig2 = m1.plot_components(forecast1)
```

### Retail Sales for Food Services & Drinking Places

```{python}
#| echo: false
df_nrs3 = subdfs["NRSV2N"]
df_nrs3 = df_nrs3[df_nrs3["ds"] >= "2018-01-01"]

m2 = Prophet()
m2.fit(df_nrs3)

future2 = m2.make_future_dataframe(periods=365)
forecast2 = m2.predict(future2)

fig3 = m2.plot(forecast2)
fig4 = m2.plot_components(forecast2)
```

-   Retail sales for Supermarkets & Other Grocery Stores compared to retail sales for Food Services shared similar constant rising path.

-   Main difference between the two is grocery and supermarket sales project on a much more constant growth line whereas restaurants and other food services are affected more heavily by widescale events (COVID in 2020 resulting in drop).

-   Best explained by the fact that grocery store products are usually necessities, whereas restaurant sales are more oriented towards consumer preference (luxury goods), making the graph more volatile.

### Import Price Index

```{python}
#| echo: false
df_nrs4 = subdfs["PMEA"]
df_nrs4 = df_nrs4[df_nrs4["ds"] >= "2018-01-01"]

m4 = Prophet()
m4.fit(df_nrs4)

future4 = m4.make_future_dataframe(periods=365)
forecast4 = m4.predict(future4)

fig7 = m4.plot(forecast4)
fig8 = m4.plot_components(forecast4)
```

### Export Price Index

```{python}
#| echo: false
df_nrs5 = subdfs["PXEA"]
df_nrs5 = df_nrs5[df_nrs5["ds"] >= "2018-01-01"]

m5 = Prophet()
m5.fit(df_nrs5)

future5 = m5.make_future_dataframe(periods=365)
forecast5 = m5.predict(future5)

fig9 = m5.plot(forecast5)
fig10 = m5.plot_components(forecast5)
```

-   Both the import and export indexes share similar forecast paths, including the huge jump around 2020.

-   In 2018, President Donald Trump implemented very similar tariffs on steel and aluminum to the current actions we are seeing today. The forecast graph for both imports and exports shows how there was a recession around the year 2018, but after the tariff war ended and Trump left office, rapid amounts of growth came with it.

-   While the tariffs today are much larger in scale compared to 2018, if we use 2018 as a precedent, we can expect a drop in exports and imports followed by massive growth once a change in office occurs.

-   Prophet's forecast still predicts stable growth will occur in both models although the data is variable.

## Correlation Grid

Below I attached a large grid of all the correlations between variables in the regression models. Deeper shades of blue signify stronger positive correlation while deeper shades of red signify stronger negative correlation between variables. Light white shades signify almost no correlation and a black shade signifies that there is not enough data to come to a statistical conclusion.

```{python}
#| echo: false
import matplotlib.pyplot as plt
from PIL import Image
import os

# Path to your image on desktop
img_path = os.path.expanduser("/Users/ericarmstrong/Desktop/tariff.png")

# Open and show the image
img = Image.open(img_path)
plt.imshow(img)
plt.axis('off')  # Hide axes
plt.show()
```

## Key Takeaways & Final Conclusions

-   Egg Prices and consumer spending had a high correlation and high statistical significance in every single model, these two variables directly affect each other

-   Spending momentum and international trade (import export index) came up as the most statistically significant control variables, they very likely have an effect on the prices of eggs

-   Egg prices will not be permanently damaged by the shortage despite it being so extreme; prophet predicts growth will eventually level out back to normal

-   Restaurant spending is much more volatile than grocery stores in predicted models. This is best explained by the fact that grocery stores primarily sell necessities whereas restaurants are more oriented towards luxury consumer preference

-   COVID mark in 2020 illustrates that large-scale global events usually do not affect sales on everyday essential items

-   The import export forecasts provide us with useful models that can be used as a precedent for Trump's new wave of tariffs in 2025. We see the steady decline in imports and exports as a result of Trump's time in office from 2018 to 2020, then the rapid growth after the change in office and COVID's conclusion